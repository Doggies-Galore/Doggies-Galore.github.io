#!/bin/bash
set -e

echo "Updating system..."
sudo apt update
sudo apt install -y \
    build-essential \
    git \
    wget \
    python3 \
    python3-pip \
    libopenblas-dev \
    cmake

# -------------------------------------------------
# Install modern CMake if needed
# -------------------------------------------------
CMAKE_VERSION=3.27.9
if ! cmake --version | grep -q "$CMAKE_VERSION"; then
    echo "Installing CMake $CMAKE_VERSION..."
    wget https://github.com/Kitware/CMake/releases/download/v$CMAKE_VERSION/cmake-$CMAKE_VERSION-linux-aarch64.sh
    chmod +x cmake-$CMAKE_VERSION-linux-aarch64.sh
    sudo ./cmake-$CMAKE_VERSION-linux-aarch64.sh --skip-license --prefix=/usr/local
fi

echo "CMake version:"
cmake --version

# -------------------------------------------------
# Clone llama.cpp
# -------------------------------------------------
if [ ! -d "llama.cpp" ]; then
    git clone https://github.com/ggerganov/llama.cpp
fi

cd llama.cpp
mkdir -p build
cd build

echo "Configuring CMake build for Jetson Nano (CGML_CUDA)..."

cmake .. \
    -DCGML_CUDA=ON \
    -DCMAKE_CUDA_ARCHITECTURES=53 \
    -DCMAKE_BUILD_TYPE=Release

echo "Building..."
cmake --build . -j$(nproc)

echo "Build complete!"
echo "Binaries: build/bin/llama-cli  and build/bin/llama-server"
echo "Create a models directory in llama.cpp/models to store your GGUF models."

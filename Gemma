llama-server -hf ggml-org/gemma-3-1b-it-GGUF --n-gpu-layers 99 --host 0.0.0.0
